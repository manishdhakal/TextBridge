# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /data: mustard_preference
  - override /model: llava_next_video
  - override /callbacks: default
  - override /trainer: default

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["test", "llava_next_video"]

seed: 12345

trainer:
  min_epochs: 1
  max_epochs: 10
  # gradient_clip_val: 0.5
  accelerator: gpu
  devices: 4
  precision: 32
  # strategy: 
    # _target_: lightning.pytorch.strategies.DeepSpeedStrategy
    # stage: 3
    # offload_optimizer: True
    # offload_parameters: True
    # _target_: lightning.pytorch.strategies.FSDPStrategy
    # sharding_strategy: FULL_SHARD
    # state_dict_type: sharded


model:
  optimizer:
    lr: 1e-5
  compile: false

data:
  batch_size: 1

logger:
  wandb:
    tags: ${tags}
    # group: "mnist"
    project: TextBridge
    name: llava_next_video_first_test

  # aim:
  #   experiment: "mnist"
