{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.42s/it]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cache_position': tensor([   0,    1,    2,  ..., 1167, 1168, 1169], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[    1,  3148,  1001,  ...,  9047, 13566, 29901]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[   0,    1,    2,  ..., 1167, 1168, 1169]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True, 'pixel_values': None, 'pixel_values_videos': tensor([[[[[-1.2813e+00, -1.2521e+00, -1.2521e+00,  ..., -1.0039e+00,\n",
      "            -9.8935e-01, -9.6015e-01],\n",
      "           [-1.2375e+00, -1.2521e+00, -1.2521e+00,  ..., -1.0039e+00,\n",
      "            -9.8935e-01, -9.6015e-01],\n",
      "           [-1.2521e+00, -1.2521e+00, -1.2521e+00,  ..., -1.0039e+00,\n",
      "            -9.8935e-01, -9.6015e-01],\n",
      "           ...,\n",
      "           [ 1.6393e-01,  2.2232e-01,  2.9531e-01,  ..., -7.2658e-01,\n",
      "            -7.2658e-01, -7.1198e-01],\n",
      "           [ 1.0553e-01,  1.6393e-01,  2.6612e-01,  ..., -7.1198e-01,\n",
      "            -7.1198e-01, -6.9738e-01],\n",
      "           [ 4.7139e-02,  1.0553e-01,  1.7853e-01,  ..., -6.9738e-01,\n",
      "            -6.9738e-01, -6.8278e-01]],\n",
      "\n",
      "          [[-1.3769e+00, -1.3469e+00, -1.3469e+00,  ..., -1.1818e+00,\n",
      "            -1.1668e+00, -1.1368e+00],\n",
      "           [-1.3319e+00, -1.3469e+00, -1.3469e+00,  ..., -1.1818e+00,\n",
      "            -1.1668e+00, -1.1368e+00],\n",
      "           [-1.3469e+00, -1.3469e+00, -1.3469e+00,  ..., -1.1818e+00,\n",
      "            -1.1668e+00, -1.1368e+00],\n",
      "           ...,\n",
      "           [-2.8134e-01, -2.2130e-01, -1.4627e-01,  ..., -6.4152e-01,\n",
      "            -6.4152e-01, -6.2651e-01],\n",
      "           [-3.4137e-01, -2.8134e-01, -1.7628e-01,  ..., -6.2651e-01,\n",
      "            -6.2651e-01, -6.1151e-01],\n",
      "           [-4.0140e-01, -3.4137e-01, -2.6633e-01,  ..., -6.1151e-01,\n",
      "            -6.1151e-01, -5.9650e-01]],\n",
      "\n",
      "          [[-1.1389e+00, -1.1105e+00, -1.1105e+00,  ..., -1.0252e+00,\n",
      "            -1.0110e+00, -9.8252e-01],\n",
      "           [-1.0963e+00, -1.1105e+00, -1.1105e+00,  ..., -1.0252e+00,\n",
      "            -1.0110e+00, -9.8252e-01],\n",
      "           [-1.1105e+00, -1.1105e+00, -1.1105e+00,  ..., -1.0252e+00,\n",
      "            -1.0110e+00, -9.8252e-01],\n",
      "           ...,\n",
      "           [ 5.5547e-02,  1.1243e-01,  1.8353e-01,  ..., -5.4170e-01,\n",
      "            -5.4170e-01, -5.2748e-01],\n",
      "           [-1.3329e-03,  5.5547e-02,  1.5509e-01,  ..., -5.2748e-01,\n",
      "            -5.2748e-01, -5.1326e-01],\n",
      "           [-5.8213e-02, -1.3329e-03,  6.9767e-02,  ..., -5.1326e-01,\n",
      "            -5.1326e-01, -4.9904e-01]]],\n",
      "\n",
      "\n",
      "         [[[-1.2229e+00, -1.2083e+00, -1.2667e+00,  ..., -8.8716e-01,\n",
      "            -9.1636e-01, -9.3096e-01],\n",
      "           [-1.2375e+00, -1.2229e+00, -1.2813e+00,  ..., -8.8716e-01,\n",
      "            -9.1636e-01, -9.3096e-01],\n",
      "           [-1.2375e+00, -1.2667e+00, -1.2229e+00,  ..., -8.8716e-01,\n",
      "            -9.1636e-01, -9.3096e-01],\n",
      "           ...,\n",
      "           [ 1.2013e-01,  1.6393e-01,  2.8071e-01,  ..., -7.1198e-01,\n",
      "            -7.2658e-01, -7.2658e-01],\n",
      "           [ 1.2013e-01,  1.7853e-01,  2.9531e-01,  ..., -7.1198e-01,\n",
      "            -7.2658e-01, -7.2658e-01],\n",
      "           [ 1.3473e-01,  2.0772e-01,  2.9531e-01,  ..., -7.1198e-01,\n",
      "            -7.2658e-01, -7.2658e-01]],\n",
      "\n",
      "          [[-1.3169e+00, -1.3019e+00, -1.3619e+00,  ..., -1.1368e+00,\n",
      "            -1.1668e+00, -1.1668e+00],\n",
      "           [-1.3319e+00, -1.3169e+00, -1.3769e+00,  ..., -1.1368e+00,\n",
      "            -1.1668e+00, -1.1668e+00],\n",
      "           [-1.3319e+00, -1.3619e+00, -1.3169e+00,  ..., -1.1368e+00,\n",
      "            -1.1668e+00, -1.1668e+00],\n",
      "           ...,\n",
      "           [-3.2636e-01, -2.8134e-01, -1.6127e-01,  ..., -6.2651e-01,\n",
      "            -6.4152e-01, -6.4152e-01],\n",
      "           [-3.2636e-01, -2.6633e-01, -1.4627e-01,  ..., -6.2651e-01,\n",
      "            -6.4152e-01, -6.4152e-01],\n",
      "           [-3.1135e-01, -2.3631e-01, -1.4627e-01,  ..., -6.2651e-01,\n",
      "            -6.4152e-01, -6.4152e-01]],\n",
      "\n",
      "          [[-1.0821e+00, -1.0678e+00, -1.1247e+00,  ..., -1.0536e+00,\n",
      "            -1.0678e+00, -1.0536e+00],\n",
      "           [-1.0963e+00, -1.0821e+00, -1.1389e+00,  ..., -1.0536e+00,\n",
      "            -1.0678e+00, -1.0536e+00],\n",
      "           [-1.0963e+00, -1.1247e+00, -1.0821e+00,  ..., -1.0536e+00,\n",
      "            -1.0678e+00, -1.0536e+00],\n",
      "           ...,\n",
      "           [ 1.2887e-02,  5.5547e-02,  1.6931e-01,  ..., -5.2748e-01,\n",
      "            -5.4170e-01, -5.4170e-01],\n",
      "           [ 1.2887e-02,  6.9767e-02,  1.8353e-01,  ..., -5.2748e-01,\n",
      "            -5.4170e-01, -5.4170e-01],\n",
      "           [ 2.7107e-02,  9.8208e-02,  1.8353e-01,  ..., -5.2748e-01,\n",
      "            -5.4170e-01, -5.4170e-01]]],\n",
      "\n",
      "\n",
      "         [[[-1.1645e+00, -9.8935e-01, -1.0769e+00,  ..., -8.8716e-01,\n",
      "            -8.7256e-01, -8.4336e-01],\n",
      "           [-1.2375e+00, -8.5796e-01, -5.5140e-01,  ..., -8.8716e-01,\n",
      "            -8.7256e-01, -8.4336e-01],\n",
      "           [-1.2959e+00, -9.1636e-01, -3.4702e-01,  ..., -8.8716e-01,\n",
      "            -8.7256e-01, -8.4336e-01],\n",
      "           ...,\n",
      "           [ 1.7853e-01,  2.6612e-01,  4.5590e-01,  ..., -8.4336e-01,\n",
      "            -8.4336e-01, -8.4336e-01],\n",
      "           [ 2.0772e-01,  2.9531e-01,  4.5590e-01,  ..., -8.4336e-01,\n",
      "            -8.4336e-01, -8.4336e-01],\n",
      "           [ 2.5152e-01,  3.0991e-01,  4.5590e-01,  ..., -8.4336e-01,\n",
      "            -8.4336e-01, -8.4336e-01]],\n",
      "\n",
      "          [[-1.2568e+00, -1.0767e+00, -1.1668e+00,  ..., -1.1518e+00,\n",
      "            -1.1368e+00, -1.1068e+00],\n",
      "           [-1.3319e+00, -9.4168e-01, -6.2651e-01,  ..., -1.1518e+00,\n",
      "            -1.1368e+00, -1.1068e+00],\n",
      "           [-1.3919e+00, -1.0017e+00, -4.1641e-01,  ..., -1.1518e+00,\n",
      "            -1.1368e+00, -1.1068e+00],\n",
      "           ...,\n",
      "           [-2.6633e-01, -1.7628e-01,  1.8820e-02,  ..., -1.1368e+00,\n",
      "            -1.1368e+00, -1.1368e+00],\n",
      "           [-2.3631e-01, -1.4627e-01,  1.8820e-02,  ..., -1.1368e+00,\n",
      "            -1.1368e+00, -1.1368e+00],\n",
      "           [-1.9129e-01, -1.3126e-01,  1.8820e-02,  ..., -1.1368e+00,\n",
      "            -1.1368e+00, -1.1368e+00]],\n",
      "\n",
      "          [[-1.0252e+00, -8.5454e-01, -9.3986e-01,  ..., -1.0252e+00,\n",
      "            -1.0110e+00, -9.8252e-01],\n",
      "           [-1.0963e+00, -7.2656e-01, -4.2793e-01,  ..., -1.0252e+00,\n",
      "            -1.0110e+00, -9.8252e-01],\n",
      "           [-1.1532e+00, -7.8344e-01, -2.2885e-01,  ..., -1.0252e+00,\n",
      "            -1.0110e+00, -9.8252e-01],\n",
      "           ...,\n",
      "           [ 1.1243e-01,  1.9775e-01,  3.8261e-01,  ..., -1.0110e+00,\n",
      "            -1.0110e+00, -1.0110e+00],\n",
      "           [ 1.4087e-01,  2.4041e-01,  3.6839e-01,  ..., -1.0110e+00,\n",
      "            -1.0110e+00, -1.0110e+00],\n",
      "           [ 1.8353e-01,  2.5463e-01,  3.6839e-01,  ..., -1.0110e+00,\n",
      "            -1.0110e+00, -1.0110e+00]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.2959e+00, -1.2959e+00, -1.2521e+00,  ..., -7.5577e-01,\n",
      "            -7.1198e-01, -6.6818e-01],\n",
      "           [-1.2229e+00, -1.2375e+00, -1.2229e+00,  ..., -7.5577e-01,\n",
      "            -7.1198e-01, -6.6818e-01],\n",
      "           [-1.2083e+00, -1.1499e+00, -1.1353e+00,  ..., -7.5577e-01,\n",
      "            -7.1198e-01, -6.6818e-01],\n",
      "           ...,\n",
      "           [ 8.5005e-01,  1.0544e+00,  1.2588e+00,  ..., -6.5359e-01,\n",
      "            -6.5359e-01, -6.5359e-01],\n",
      "           [ 9.5224e-01,  1.1566e+00,  1.3172e+00,  ..., -6.5359e-01,\n",
      "            -6.5359e-01, -6.5359e-01],\n",
      "           [ 1.0106e+00,  1.2150e+00,  1.3318e+00,  ..., -6.5359e-01,\n",
      "            -6.5359e-01, -6.5359e-01]],\n",
      "\n",
      "          [[-1.3919e+00, -1.3919e+00, -1.3469e+00,  ..., -9.4168e-01,\n",
      "            -9.1166e-01, -8.8165e-01],\n",
      "           [-1.3169e+00, -1.3319e+00, -1.3169e+00,  ..., -9.4168e-01,\n",
      "            -9.1166e-01, -8.8165e-01],\n",
      "           [-1.3019e+00, -1.2418e+00, -1.2268e+00,  ..., -9.4168e-01,\n",
      "            -9.1166e-01, -8.8165e-01],\n",
      "           ...,\n",
      "           [ 4.2403e-01,  6.3414e-01,  8.1423e-01,  ..., -5.8149e-01,\n",
      "            -5.8149e-01, -5.8149e-01],\n",
      "           [ 5.2908e-01,  7.3919e-01,  9.0428e-01,  ..., -5.8149e-01,\n",
      "            -5.8149e-01, -5.8149e-01],\n",
      "           [ 5.8911e-01,  7.9922e-01,  9.1929e-01,  ..., -5.8149e-01,\n",
      "            -5.8149e-01, -5.8149e-01]],\n",
      "\n",
      "          [[-1.1532e+00, -1.1532e+00, -1.1105e+00,  ..., -8.5454e-01,\n",
      "            -8.4032e-01, -8.2610e-01],\n",
      "           [-1.0821e+00, -1.0963e+00, -1.0821e+00,  ..., -8.5454e-01,\n",
      "            -8.4032e-01, -8.2610e-01],\n",
      "           [-1.0678e+00, -1.0110e+00, -9.9674e-01,  ..., -8.5454e-01,\n",
      "            -8.4032e-01, -8.2610e-01],\n",
      "           ...,\n",
      "           [ 7.2389e-01,  9.2297e-01,  1.1078e+00,  ..., -4.4215e-01,\n",
      "            -4.4215e-01, -4.4215e-01],\n",
      "           [ 8.2343e-01,  1.0225e+00,  1.1789e+00,  ..., -4.4215e-01,\n",
      "            -4.4215e-01, -4.4215e-01],\n",
      "           [ 8.8031e-01,  1.0794e+00,  1.1932e+00,  ..., -4.4215e-01,\n",
      "            -4.4215e-01, -4.4215e-01]]],\n",
      "\n",
      "\n",
      "         [[[-1.2667e+00, -1.2667e+00, -1.2375e+00,  ..., -9.8935e-01,\n",
      "            -9.8935e-01, -9.6015e-01],\n",
      "           [-1.2229e+00, -1.2083e+00, -1.2375e+00,  ..., -9.8935e-01,\n",
      "            -9.8935e-01, -9.6015e-01],\n",
      "           [-1.2667e+00, -1.2229e+00, -1.2083e+00,  ..., -9.8935e-01,\n",
      "            -9.8935e-01, -9.6015e-01],\n",
      "           ...,\n",
      "           [ 2.6612e-01,  2.8071e-01,  4.4130e-01,  ..., -6.9738e-01,\n",
      "            -6.9738e-01, -6.9738e-01],\n",
      "           [ 2.3692e-01,  2.9531e-01,  4.2670e-01,  ..., -6.9738e-01,\n",
      "            -6.9738e-01, -6.9738e-01],\n",
      "           [ 2.5152e-01,  3.2451e-01,  4.5590e-01,  ..., -6.9738e-01,\n",
      "            -6.9738e-01, -6.9738e-01]],\n",
      "\n",
      "          [[-1.3169e+00, -1.3169e+00, -1.2869e+00,  ..., -1.1668e+00,\n",
      "            -1.1668e+00, -1.1368e+00],\n",
      "           [-1.2718e+00, -1.2568e+00, -1.2869e+00,  ..., -1.1668e+00,\n",
      "            -1.1668e+00, -1.1368e+00],\n",
      "           [-1.3169e+00, -1.2718e+00, -1.2568e+00,  ..., -1.1668e+00,\n",
      "            -1.1668e+00, -1.1368e+00],\n",
      "           ...,\n",
      "           [-1.7628e-01, -1.4627e-01, -1.1196e-02,  ..., -6.2651e-01,\n",
      "            -6.2651e-01, -6.2651e-01],\n",
      "           [-2.0630e-01, -1.4627e-01, -2.6204e-02,  ..., -6.2651e-01,\n",
      "            -6.2651e-01, -6.2651e-01],\n",
      "           [-1.9129e-01, -1.1625e-01,  1.8820e-02,  ..., -6.2651e-01,\n",
      "            -6.2651e-01, -6.2651e-01]],\n",
      "\n",
      "          [[-1.0963e+00, -1.0963e+00, -1.0678e+00,  ..., -1.0110e+00,\n",
      "            -1.0110e+00, -9.8252e-01],\n",
      "           [-1.0536e+00, -1.0394e+00, -1.0678e+00,  ..., -1.0110e+00,\n",
      "            -1.0110e+00, -9.8252e-01],\n",
      "           [-1.0963e+00, -1.0536e+00, -1.0394e+00,  ..., -1.0110e+00,\n",
      "            -1.0110e+00, -9.8252e-01],\n",
      "           ...,\n",
      "           [ 1.9775e-01,  2.1197e-01,  3.8261e-01,  ..., -4.8482e-01,\n",
      "            -4.8482e-01, -4.8482e-01],\n",
      "           [ 1.6931e-01,  2.2619e-01,  3.6839e-01,  ..., -4.8482e-01,\n",
      "            -4.8482e-01, -4.8482e-01],\n",
      "           [ 1.8353e-01,  2.5463e-01,  3.9683e-01,  ..., -4.8482e-01,\n",
      "            -4.8482e-01, -4.8482e-01]]],\n",
      "\n",
      "\n",
      "         [[[-1.2375e+00, -1.2521e+00, -1.2375e+00,  ..., -1.0039e+00,\n",
      "            -9.7475e-01, -1.0039e+00],\n",
      "           [-1.2375e+00, -1.2229e+00, -1.2083e+00,  ..., -1.0039e+00,\n",
      "            -9.7475e-01, -1.0039e+00],\n",
      "           [-1.2813e+00, -1.2813e+00, -1.2521e+00,  ..., -1.0039e+00,\n",
      "            -9.8935e-01, -9.8935e-01],\n",
      "           ...,\n",
      "           [ 8.7925e-01,  1.0252e+00,  1.0982e+00,  ..., -6.2439e-01,\n",
      "            -6.2439e-01, -6.2439e-01],\n",
      "           [ 8.9385e-01,  9.8144e-01,  1.0252e+00,  ..., -6.2439e-01,\n",
      "            -6.2439e-01, -6.2439e-01],\n",
      "           [ 8.9385e-01,  9.5224e-01,  9.9604e-01,  ..., -6.2439e-01,\n",
      "            -6.2439e-01, -6.2439e-01]],\n",
      "\n",
      "          [[-1.2869e+00, -1.3019e+00, -1.2869e+00,  ..., -1.2118e+00,\n",
      "            -1.1818e+00, -1.2118e+00],\n",
      "           [-1.2869e+00, -1.2718e+00, -1.2568e+00,  ..., -1.2118e+00,\n",
      "            -1.1818e+00, -1.2118e+00],\n",
      "           [-1.3319e+00, -1.3319e+00, -1.3019e+00,  ..., -1.2118e+00,\n",
      "            -1.1818e+00, -1.1968e+00],\n",
      "           ...,\n",
      "           [ 4.9907e-01,  6.7916e-01,  7.3919e-01,  ..., -5.5148e-01,\n",
      "            -5.5148e-01, -5.5148e-01],\n",
      "           [ 5.1408e-01,  6.3414e-01,  6.7916e-01,  ..., -5.5148e-01,\n",
      "            -5.5148e-01, -5.5148e-01],\n",
      "           [ 5.1408e-01,  6.0412e-01,  6.4915e-01,  ..., -5.5148e-01,\n",
      "            -5.5148e-01, -5.5148e-01]],\n",
      "\n",
      "          [[-1.0678e+00, -1.0821e+00, -1.0678e+00,  ..., -1.0394e+00,\n",
      "            -1.0110e+00, -1.0394e+00],\n",
      "           [-1.0678e+00, -1.0536e+00, -1.0394e+00,  ..., -1.0394e+00,\n",
      "            -1.0110e+00, -1.0394e+00],\n",
      "           [-1.1105e+00, -1.1105e+00, -1.0821e+00,  ..., -1.0394e+00,\n",
      "            -1.0110e+00, -1.0252e+00],\n",
      "           ...,\n",
      "           [ 8.2343e-01,  9.7985e-01,  1.0652e+00,  ..., -4.1371e-01,\n",
      "            -4.1371e-01, -4.1371e-01],\n",
      "           [ 8.2343e-01,  9.3719e-01,  9.9407e-01,  ..., -4.1371e-01,\n",
      "            -4.1371e-01, -4.1371e-01],\n",
      "           [ 8.3765e-01,  9.0875e-01,  9.6563e-01,  ..., -4.1371e-01,\n",
      "            -4.1371e-01, -4.1371e-01]]]]], device='cuda:0'), 'image_sizes': None}\n",
      "{'cache_position': tensor([1170], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[450]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1170]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1171], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[27448]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1171]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1172], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[297]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1172]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1173], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[445]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1173]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1174], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[4863]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1174]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1175], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[5304]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1175]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1176], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[515]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1176]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1177], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[278]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1177]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1178], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[15668]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1178]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1179], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[322]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1179]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1180], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[19981]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1180]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1181], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[4362]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1181]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1182], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[5469]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1182]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1183], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[310]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1183]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1184], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[278]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1184]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1185], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[6434]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1185]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1186], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[29889]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1186]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1187], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[450]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1187]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1188], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[24354]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1188]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1189], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[338]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1189]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1190], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[591]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1190]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1191], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[4362]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1191]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1192], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[12917]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1192]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1193], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[267]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1193]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1194], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[322]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1194]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1195], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[5692]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1195]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1196], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[304]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1196]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1197], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[367]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1197]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1198], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[5183]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1199], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[263]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1199]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1200], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[3143]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1200]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1201], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[29892]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1201]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1202], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[607]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1202]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1203], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[338]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1203]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1204], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[263]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1204]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1205], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[3165]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1205]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1206], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[20657]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1206]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1207], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[322]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1207]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1208], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[19981]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1208]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1209], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[4362]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1209]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1210], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[11126]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1210]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1211], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[1363]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1211]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1212], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[289]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1212]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1213], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[370]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1213]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1214], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[583]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1214]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1215], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[526]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1215]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1216], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[12234]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1216]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1217], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[451]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1217]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1218], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[3806]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1218]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1219], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[304]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1219]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1220], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[367]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1220]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1221], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[2221]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1221]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1222], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[304]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1222]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1223], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[1303]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1223]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1224], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[472]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1224]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1225], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[1316]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1225]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1226], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[263]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1226]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1227], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[4123]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1227]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1228], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[5046]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1228]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1229], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[29889]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1229]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1230], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[450]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1230]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1231], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[12917]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1231]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1232], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[267]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1232]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1233], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[788]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1233]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1234], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[263]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1234]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1235], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[6023]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1235]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1236], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[310]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1236]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1237], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[377]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1237]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1238], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[9893]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1238]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1239], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[29891]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1239]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1240], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[322]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1240]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1241], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[278]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1241]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1242], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[24354]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1242]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1243], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[29915]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1243]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1244], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[29879]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1244]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1245], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[4603]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1245]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1246], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[322]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1246]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1247], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[8820]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1247]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1248], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[4368]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1248]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1249], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[393]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1249]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1250], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[896]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1250]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1251], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[526]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1251]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1252], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[24344]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1252]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1253], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[3033]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1253]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1254], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[2124]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1254]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1255], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[287]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1255]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1256], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[297]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1257], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[278]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1257]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1258], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[3143]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1258]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1259], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[29892]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1259]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1260], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[607]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1260]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1261], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[338]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1261]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1262], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[263]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1262]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1263], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[1708]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1263]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1264], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[1319]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1264]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1265], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[322]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1265]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1266], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[626]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1266]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1267], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[4746]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1267]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1268], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[2011]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1268]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1269], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[764]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1269]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1270], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[284]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1270]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1271], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[310]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1271]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1272], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[263]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1272]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1273], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[2278]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1273]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1274], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[29915]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1274]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1275], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[29879]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1275]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1276], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[27742]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1276]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1277], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[322]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1277]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1278], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[28038]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1278]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1279], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[29889]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1279]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1280], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[450]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1280]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1281], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[4863]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1281]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1282], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[4332]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1282]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1283], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[1973]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1283]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1284], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[263]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1284]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1285], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[3256]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1285]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1286], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[310]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1286]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1287], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[21458]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1287]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1288], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[663]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1288]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1289], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[322]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1289]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1290], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[1708]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1290]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1291], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[1319]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1291]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1292], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[2264]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1292]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1293], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[393]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1293]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1294], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[508]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1294]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1295], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[367]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1295]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1296], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[3595]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1296]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1297], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[408]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1297]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1298], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[274]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1298]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1299], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[1082]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1299]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1300], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[322]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1300]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1301], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[22684]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1301]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1302], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[292]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1302]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1303], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[304]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1303]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1304], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[1776]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1304]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1305], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[414]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1305]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n",
      "{'cache_position': tensor([1306], device='cuda:0'), 'past_key_values': <transformers.cache_utils.DynamicCache object at 0x725516262e20>, 'input_ids': tensor([[29889]], device='cuda:0'), 'inputs_embeds': None, 'position_ids': tensor([[1306]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'logits_to_keep': 1, 'use_cache': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"USER: \\nWhy is this video funny? ASSISTANT: The humor in this video comes from the unexpected and endearing nature of the situation. The baby is wearing glasses and appears to be reading a book, which is a humorous and endearing sight because babies are typically not expected to be able to read at such a young age. The glasses add a touch of whimsy and the baby's expression and actions suggest that they are deeply engrossed in the book, which is a playful and amusing portrayal of a child's curiosity and imagination. The video captures a moment of innocence and playfulness that can be seen as cute and entertaining to viewers.\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "import av\n",
    "import torch\n",
    "from huggingface_hub import hf_hub_download\n",
    "from transformers import AutoProcessor, LlavaNextVideoForConditionalGeneration\n",
    "\n",
    "\n",
    "def read_video_pyav(container, indices):\n",
    "    \"\"\"\n",
    "    Decode the video with PyAV decoder.\n",
    "    Args:\n",
    "        container (`av.container.input.InputContainer`): PyAV container.\n",
    "        indices (`List[int]`): List of frame indices to decode.\n",
    "    Returns:\n",
    "        result (np.ndarray): np array of decoded frames of shape (num_frames, height, width, 3).\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    container.seek(0)\n",
    "    start_index = indices[0]\n",
    "    end_index = indices[-1]\n",
    "    for i, frame in enumerate(container.decode(video=0)):\n",
    "        if i > end_index:\n",
    "            break\n",
    "        if i >= start_index and i in indices:\n",
    "            frames.append(frame)\n",
    "    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])\n",
    "\n",
    "\n",
    "model = LlavaNextVideoForConditionalGeneration.from_pretrained(\n",
    "    \"llava-hf/LLaVA-NeXT-Video-7B-hf\", device_map=\"auto\", torch_dtype=torch.float16\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(\"llava-hf/LLaVA-NeXT-Video-7B-hf\")\n",
    "\n",
    "prompt = \"USER: <video>\\nWhy is this video funny? ASSISTANT:\"\n",
    "video_path = hf_hub_download(\n",
    "    repo_id=\"raushan-testing-hf/videos-test\",\n",
    "    filename=\"sample_demo_1.mp4\",\n",
    "    repo_type=\"dataset\",\n",
    ")\n",
    "container = av.open(video_path)\n",
    "\n",
    "# sample uniformly 8 frames from the video (model was trained with 32 frames per video, but this video is short)\n",
    "total_frames = container.streams.video[0].frames\n",
    "indices = np.arange(0, total_frames, total_frames / 8).astype(int)\n",
    "clip = read_video_pyav(container, indices)\n",
    "inputs_video = processor(text=prompt, videos=clip, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "inputs_video = dict(inputs_video)\n",
    "# print(inputs_video.input_ids[:, -10:])\n",
    "# load an image to generate from an image\n",
    "# prompt = \"USER:<image>\\nWhat is shown in this image? ASSISTANT:\"\n",
    "# url = \"https://www.ilankelman.org/stopsigns/australia.jpg\"\n",
    "# image = Image.open(requests.get(url, stream=True).raw)\n",
    "# inputs_image = processor(text=prompt, images=image, return_tensors=\"pt\").to(\n",
    "#     model.device\n",
    "# )\n",
    "\n",
    "\n",
    "def update_positional_and_cache_ids(inputs_video, first_input=True):\n",
    "    \"\"\"\n",
    "    Update the positional ids of the video.\n",
    "    Args:\n",
    "        inputs_video (`Dict`): Dictionary containing the input tensors.\n",
    "        first_input (`bool`): Whether this is the first input or not in auto-regressive generation.\n",
    "    Returns:\n",
    "        inputs_video (`Dict`): Updated dictionary with new positional ids.\n",
    "    \"\"\"\n",
    "    device = inputs_video[\"input_ids\"].device\n",
    "    inputs_video = dict(inputs_video)\n",
    "    if first_input:\n",
    "        batch_size, num_tokens = inputs_video[\"input_ids\"].shape[:2]\n",
    "        ids = torch.arange(num_tokens, device=device)\n",
    "        inputs_video[\"cache_position\"] = ids\n",
    "        inputs_video[\"postional_ids\"] = ids.expand(batch_size, num_tokens)\n",
    "    else:\n",
    "        batch_size = inputs_video[\"input_ids\"].shape[0]\n",
    "        ids = torch.max(inputs_video[\"postional_ids\"]) + 1\n",
    "        inputs_video[\"cache_position\"] = ids.expand(batch_size)\n",
    "        inputs_video[\"postional_ids\"] = ids.expand(batch_size, 1)\n",
    "    \n",
    "    return inputs_video\n",
    "\n",
    "\n",
    "def prepare_inputs_for_generation(inputs_video, predicted_outputs=None):\n",
    "    \"\"\"\n",
    "    Prepare the inputs for generation.\n",
    "    Args:\n",
    "        inputs_video (`Dict`): Dictionary containing the input tensors.\n",
    "        predicted_outpur (`Dict | None`): The predicted outputs from the model with `inputs_video`. \n",
    "            Contains `logits` and `past_key_values`. None if this is the first input.\n",
    "    Returns:\n",
    "        inputs_video (`Dict`): Updated dictionary with new input tensors.\n",
    "    \"\"\"\n",
    "    device = inputs_video[\"input_ids\"].device\n",
    "    inputs_video = dict(inputs_video)\n",
    "    \n",
    "    if predicted_outputs is None:\n",
    "        inputs_video = update_positional_and_cache_ids(inputs_video, first_input=True)\n",
    "        inputs_video[\"past_key_values\"] = None\n",
    "        inputs_video[\"logits_to_keep\"] = 1\n",
    "        inputs_video[\"use_cache\"] = True\n",
    "    else:\n",
    "        inputs_video[\"input_ids\"] = predicted_outputs[\"logits\"].argmax(dim=-1)\n",
    "        inputs_video[\"attention_mask\"] = torch.cat(\n",
    "            [\n",
    "                torch.ones(\n",
    "                    (inputs_video[\"attention_mask\"].shape[0], 1), device=device\n",
    "                ),\n",
    "                inputs_video[\"attention_mask\"],\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "        inputs_video = update_positional_and_cache_ids(inputs_video, first_input=False)\n",
    "        inputs_video[\"past_key_values\"] = predicted_outputs[\"past_key_values\"]\n",
    "        inputs_video[\"logits_to_keep\"] = 1\n",
    "        inputs_video[\"use_cache\"] = True\n",
    "        inputs_video[\"pixel_values_videos\"] = None\n",
    "    return inputs_video\n",
    "\n",
    "# print(inputs_video)\n",
    "# Generate from video\n",
    "\n",
    "generated_output = model.generate(\n",
    "    **inputs_video, max_new_tokens=200, output_logits=True, return_dict_in_generate=True\n",
    ")\n",
    "processor.batch_decode(\n",
    "    generated_output.sequences,\n",
    "    skip_special_tokens=True,\n",
    "    clean_up_tokenization_spaces=False,\n",
    ")[0]\n",
    "\n",
    "\n",
    "# max_new_tokens = 50\n",
    "# with torch.no_grad():\n",
    "#     # inputs_video = processor(text=prompt, videos=clip, return_tensors=\"pt\").to(model.device)\n",
    "#     # inputs_video.input_ids = inputs_video.input_ids[:, :1]\n",
    "#     # inputs_video.attention_mask = inputs_video.attention_mask[:, :1]\n",
    "#     # inputs_video.video_mask = inputs_video.video_mask[:, :1]\n",
    "#     # inputs_video.video_attention_mask = inputs_video.video_attention_mask[:, :1]\n",
    "#     # inputs_video.video_position_ids = inputs_video.video_position_ids[:, :1]\n",
    "#     for _ in range(max_new_tokens):\n",
    "#         # print(inputs_video.input_ids.shape)\n",
    "#         output = model(\n",
    "#             input_ids=inputs_video.input_ids,\n",
    "#             attention_mask=inputs_video.attention_mask,\n",
    "#             pixel_values_videos=inputs_video.pixel_values_videos,\n",
    "#             past_key_values=inputs_video.past_key_values,\n",
    "#             logits_to_keep=1,\n",
    "#         )\n",
    "#         # output = model(logits_to_keep=1, **inputs_video)\n",
    "#         predicted_ids = output.logits.argmax(-1)\n",
    "#         print(predicted_ids)\n",
    "#         # inputs_video.input_ids = torch.cat([inputs_video.input_ids, predicted_ids], dim=1)\n",
    "\n",
    "#         # inputs_video = inputs_video\n",
    "#         inputs_video.input_ids = predicted_ids\n",
    "#         inputs_video.attention_mask = torch.cat(\n",
    "#             [\n",
    "#                 torch.ones(\n",
    "#                     (inputs_video.attention_mask.shape[0], 1), device=model.device\n",
    "#                 ),\n",
    "#                 inputs_video.attention_mask,\n",
    "#             ],\n",
    "#             dim=1,\n",
    "#         )\n",
    "#         inputs_video.past_key_values = output.past_key_values\n",
    "#         inputs_video.pixel_values_videos = None\n",
    "#         positional_ids =\n",
    "# inputs_video.\n",
    "\n",
    "# # Generate from image\n",
    "# generate_ids = model.generate(**inputs_image, max_new_tokens=50)\n",
    "# processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n",
      "torch.Size([1, 1, 32064])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m inputs_video \u001b[38;5;241m=\u001b[39m prepare_inputs_for_generation(inputs_video, predicted_outputs)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# print(inputs_video)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m predicted_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs_video\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(predicted_outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/transformers/models/llava_next_video/modeling_llava_next_video.py:764\u001b[0m, in \u001b[0;36mLlavaNextVideoForConditionalGeneration.forward\u001b[0;34m(self, input_ids, pixel_values, pixel_values_videos, image_sizes, attention_mask, position_ids, past_key_values, inputs_embeds, vision_feature_layer, vision_feature_select_strategy, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **lm_kwargs)\u001b[0m\n\u001b[1;32m    756\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m inputs_embeds\u001b[38;5;241m.\u001b[39mmasked_scatter(special_image_mask, video_features)\n\u001b[1;32m    758\u001b[0m \u001b[38;5;66;03m# print(\"inputs_embeds shape\", inputs_embeds.shape)\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;66;03m# print(\"attention_mask.shape\", attention_mask.shape)\u001b[39;00m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;66;03m# if len(past_key_values) > 0:\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;66;03m#     print(\"past_key_values\", len(past_key_values))\u001b[39;00m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;66;03m#     print(\"past_key_values\", past_key_values[0][0].shape, past_key_values[0][1].shape)\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlanguage_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits_to_keep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_to_keep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    780\u001b[0m \u001b[38;5;66;03m# print(\"logits shape\", logits.shape)\u001b[39;00m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;66;03m# print(\"logits_to_keep\", logits_to_keep)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/transformers/utils/generic.py:965\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 965\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    967\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:821\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    817\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m    818\u001b[0m )\n\u001b[1;32m    820\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 821\u001b[0m outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m    835\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/transformers/utils/generic.py:965\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 965\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    967\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:571\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    560\u001b[0m         partial(decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mflash_attn_kwargs),\n\u001b[1;32m    561\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    568\u001b[0m         position_embeddings,\n\u001b[1;32m    569\u001b[0m     )\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 571\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    583\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:318\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 318\u001b[0m hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:254\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    253\u001b[0m key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 254\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    256\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m position_embeddings\n\u001b[1;32m    257\u001b[0m query_states, key_states \u001b[38;5;241m=\u001b[39m apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniconda3/envs/textbridge/lib/python3.9/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_new_tokens = 200\n",
    "\n",
    "with torch.no_grad():\n",
    "    predicted_outputs = None\n",
    "    for i in range(max_new_tokens):\n",
    "        inputs_video = prepare_inputs_for_generation(inputs_video, predicted_outputs)\n",
    "        # print(inputs_video)\n",
    "        predicted_outputs = model(**inputs_video)\n",
    "        print(predicted_outputs[\"logits\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3148, 1001, 29901, 29871, 32000, 13, 11008, 338, 445, 4863, 2090, 1460, 29973, 319, 1799, 9047, 13566, 29901, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 15043, 727, 29991]], 'attention_mask': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer([\"USER: <video>\\nWhy is this video funny? ASSISTANT:</s>\", \"Hello there!\"],\n",
    "    max_length=50,\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    add_special_tokens=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 100])\n",
      "torch.Size([3, 100])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "# Example of target with class indices\n",
    "loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "input = torch.randn(3, 5,  100, requires_grad=True)\n",
    "target = torch.empty(3, 100, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)\n",
    "print(output.shape)\n",
    "output.mean().backward()\n",
    "\n",
    "# Example of target with class probabilities\n",
    "input = torch.randn(3,  5, 100, requires_grad=True)\n",
    "target = torch.randn(3, 5, 100).softmax(dim=1)\n",
    "output = loss(input, target)\n",
    "print(output.shape)\n",
    "output.mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"USER: \\nWhy is this video funny? ASSISTANT: The humor in this video comes from the unexpected and endearing situation of a young child, who appears to be a baby or toddler, attempting to read a book. The child's small size and the fact that they are reading a book\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': tensor([1, 2]), 'b': 2} {'a': tensor([2, 1]), 'b': 2}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "dict1 = {'a': torch.tensor([1,2]), 'b': 2}\n",
    "dict2 = dict1.copy()\n",
    "\n",
    "dict2['a'] = torch.tensor([2,1])  # {'a': 1, 'b': 2}\n",
    "\n",
    "print(dict1, dict2)  # {'a': 1, 'b': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textbridge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
